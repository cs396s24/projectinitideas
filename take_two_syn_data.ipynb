{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "def simulate_data(N):\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2023-12-31'\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    N = len(dates)\n",
    "    \n",
    "    # Economic variables\n",
    "    columns = ['Federal Funds Rate', 'Unemployment Rate', 'Yield Curve Inversion',\n",
    "               'VIX', 'BCI', 'CCI', 'GDP Growth']\n",
    "    df = pd.DataFrame(index=dates, columns=columns)\n",
    "    \n",
    "    # Initial values based on realistic estimates\n",
    "    df.loc[dates[0], :] = [1.5, 5.0, 0, 15, 100, 100, 2.5]\n",
    "\n",
    "    # Simulate each variable with random walk and shocks\n",
    "    np.random.seed(0)\n",
    "    for t in range(1, N):\n",
    "        df.iloc[t]['Federal Funds Rate'] = df.iloc[t-1]['Federal Funds Rate'] + np.random.normal(0, 0.1)\n",
    "        df.iloc[t]['Unemployment Rate'] = max(0, df.iloc[t-1]['Unemployment Rate'] + np.random.normal(0, 0.2))\n",
    "        df.iloc[t]['Yield Curve Inversion'] = int(np.random.rand() > 0.8)\n",
    "        df.iloc[t]['VIX'] = max(10, df.iloc[t-1]['VIX'] + np.random.normal(0, 2))\n",
    "        df.iloc[t]['BCI'] = max(50, df.iloc[t-1]['BCI'] + np.random.normal(0, 1))\n",
    "        df.iloc[t]['CCI'] = max(50, df.iloc[t-1]['CCI'] + np.random.normal(0, 1))\n",
    "        df.iloc[t]['GDP Growth'] = df.iloc[t-1]['GDP Growth'] + np.random.normal(0, 0.5)\n",
    "\n",
    "    # Calculate monthly changes for relevant columns\n",
    "    for col in ['VIX', 'BCI', 'CCI', 'GDP Growth']:\n",
    "        df[col + ' % Change'] = df[col].pct_change() * 100\n",
    "    \n",
    "    # Drop rows with any NaN values (typically the first row)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing causality to GDP Growth from VIX % Change:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=2.9163  , p=0.0888  , df_denom=283, df_num=1\n",
      "ssr based chi2 test:   chi2=2.9472  , p=0.0860  , df=1\n",
      "likelihood ratio test: chi2=2.9322  , p=0.0868  , df=1\n",
      "parameter F test:         F=2.9163  , p=0.0888  , df_denom=283, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.8496  , p=0.0595  , df_denom=280, df_num=2\n",
      "ssr based chi2 test:   chi2=5.8009  , p=0.0550  , df=2\n",
      "likelihood ratio test: chi2=5.7427  , p=0.0566  , df=2\n",
      "parameter F test:         F=2.8496  , p=0.0595  , df_denom=280, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.9382  , p=0.1236  , df_denom=277, df_num=3\n",
      "ssr based chi2 test:   chi2=5.9616  , p=0.1135  , df=3\n",
      "likelihood ratio test: chi2=5.8998  , p=0.1166  , df=3\n",
      "parameter F test:         F=1.9382  , p=0.1236  , df_denom=277, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.2893  , p=0.2744  , df_denom=274, df_num=4\n",
      "ssr based chi2 test:   chi2=5.3268  , p=0.2554  , df=4\n",
      "likelihood ratio test: chi2=5.2773  , p=0.2600  , df=4\n",
      "parameter F test:         F=1.2893  , p=0.2744  , df_denom=274, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.5399  , p=0.1776  , df_denom=271, df_num=5\n",
      "ssr based chi2 test:   chi2=8.0123  , p=0.1556  , df=5\n",
      "likelihood ratio test: chi2=7.9006  , p=0.1618  , df=5\n",
      "parameter F test:         F=1.5399  , p=0.1776  , df_denom=271, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.1603  , p=0.3280  , df_denom=268, df_num=6\n",
      "ssr based chi2 test:   chi2=7.2992  , p=0.2941  , df=6\n",
      "likelihood ratio test: chi2=7.2060  , p=0.3022  , df=6\n",
      "parameter F test:         F=1.1603  , p=0.3280  , df_denom=268, df_num=6\n",
      "\n",
      "Testing causality to GDP Growth from BCI % Change:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.3699  , p=0.2428  , df_denom=283, df_num=1\n",
      "ssr based chi2 test:   chi2=1.3844  , p=0.2394  , df=1\n",
      "likelihood ratio test: chi2=1.3811  , p=0.2399  , df=1\n",
      "parameter F test:         F=1.3699  , p=0.2428  , df_denom=283, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.7722  , p=0.4630  , df_denom=280, df_num=2\n",
      "ssr based chi2 test:   chi2=1.5720  , p=0.4557  , df=2\n",
      "likelihood ratio test: chi2=1.5677  , p=0.4566  , df=2\n",
      "parameter F test:         F=0.7722  , p=0.4630  , df_denom=280, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.6052  , p=0.6122  , df_denom=277, df_num=3\n",
      "ssr based chi2 test:   chi2=1.8614  , p=0.6017  , df=3\n",
      "likelihood ratio test: chi2=1.8553  , p=0.6030  , df=3\n",
      "parameter F test:         F=0.6052  , p=0.6122  , df_denom=277, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.5143  , p=0.7253  , df_denom=274, df_num=4\n",
      "ssr based chi2 test:   chi2=2.1247  , p=0.7128  , df=4\n",
      "likelihood ratio test: chi2=2.1168  , p=0.7143  , df=4\n",
      "parameter F test:         F=0.5143  , p=0.7253  , df_denom=274, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.3071  , p=0.9084  , df_denom=271, df_num=5\n",
      "ssr based chi2 test:   chi2=1.5980  , p=0.9015  , df=5\n",
      "likelihood ratio test: chi2=1.5935  , p=0.9020  , df=5\n",
      "parameter F test:         F=0.3071  , p=0.9084  , df_denom=271, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.6878  , p=0.6597  , df_denom=268, df_num=6\n",
      "ssr based chi2 test:   chi2=4.3270  , p=0.6325  , df=6\n",
      "likelihood ratio test: chi2=4.2940  , p=0.6370  , df=6\n",
      "parameter F test:         F=0.6878  , p=0.6597  , df_denom=268, df_num=6\n",
      "\n",
      "Testing causality to GDP Growth from CCI % Change:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=2.8906  , p=0.0902  , df_denom=283, df_num=1\n",
      "ssr based chi2 test:   chi2=2.9213  , p=0.0874  , df=1\n",
      "likelihood ratio test: chi2=2.9064  , p=0.0882  , df=1\n",
      "parameter F test:         F=2.8906  , p=0.0902  , df_denom=283, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.5549  , p=0.2130  , df_denom=280, df_num=2\n",
      "ssr based chi2 test:   chi2=3.1653  , p=0.2054  , df=2\n",
      "likelihood ratio test: chi2=3.1479  , p=0.2072  , df=2\n",
      "parameter F test:         F=1.5549  , p=0.2130  , df_denom=280, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.7678  , p=0.1535  , df_denom=277, df_num=3\n",
      "ssr based chi2 test:   chi2=5.4373  , p=0.1424  , df=3\n",
      "likelihood ratio test: chi2=5.3859  , p=0.1456  , df=3\n",
      "parameter F test:         F=1.7678  , p=0.1535  , df_denom=277, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.5691  , p=0.0384  , df_denom=274, df_num=4\n",
      "ssr based chi2 test:   chi2=10.6140 , p=0.0313  , df=4\n",
      "likelihood ratio test: chi2=10.4198 , p=0.0339  , df=4\n",
      "parameter F test:         F=2.5691  , p=0.0384  , df_denom=274, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.0616  , p=0.0105  , df_denom=271, df_num=5\n",
      "ssr based chi2 test:   chi2=15.9293 , p=0.0070  , df=5\n",
      "likelihood ratio test: chi2=15.4957 , p=0.0084  , df=5\n",
      "parameter F test:         F=3.0616  , p=0.0105  , df_denom=271, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.3696  , p=0.0301  , df_denom=268, df_num=6\n",
      "ssr based chi2 test:   chi2=14.9075 , p=0.0210  , df=6\n",
      "likelihood ratio test: chi2=14.5255 , p=0.0243  , df=6\n",
      "parameter F test:         F=2.3696  , p=0.0301  , df_denom=268, df_num=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:22: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['Federal Funds Rate'] = df.iloc[t-1]['Federal Funds Rate'] + np.random.normal(0, 0.1)\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:23: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['Unemployment Rate'] = max(0, df.iloc[t-1]['Unemployment Rate'] + np.random.normal(0, 0.2))\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['Yield Curve Inversion'] = int(np.random.rand() > 0.8)\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:25: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['VIX'] = max(10, df.iloc[t-1]['VIX'] + np.random.normal(0, 2))\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['BCI'] = max(50, df.iloc[t-1]['BCI'] + np.random.normal(0, 1))\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:27: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['CCI'] = max(50, df.iloc[t-1]['CCI'] + np.random.normal(0, 1))\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df.iloc[t]['GDP Growth'] = df.iloc[t-1]['GDP Growth'] + np.random.normal(0, 0.5)\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col + ' % Change'] = df[col].pct_change() * 100\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col + ' % Change'] = df[col].pct_change() * 100\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col + ' % Change'] = df[col].pct_change() * 100\n",
      "C:\\Users\\ellac\\AppData\\Local\\Temp\\ipykernel_67036\\3955283531.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col + ' % Change'] = df[col].pct_change() * 100\n",
      "c:\\Users\\ellac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:1545: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:1545: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:1545: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def test_granger_causality(data, maxlag=6):\n",
    "    variables = ['VIX % Change', 'BCI % Change', 'CCI % Change']\n",
    "    results = {}\n",
    "    for var in variables:\n",
    "        print(f\"\\nTesting causality to GDP Growth from {var}:\")\n",
    "        result = grangercausalitytests(data[['GDP Growth % Change', var]], maxlag=maxlag, verbose=True)\n",
    "        results[var] = result\n",
    "    return results\n",
    "\n",
    "# Generate and process data\n",
    "data = simulate_data(288)\n",
    "\n",
    "# Execute the Granger causality tests\n",
    "granger_results = test_granger_causality(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
